\subsection{LS-Queries Using the \btsr}
\label{sec:ls_q_btsr}
A straightforward approach for answering LS-queries would be to use a spatial index to first filter by spatial distance and then perform a sequential scan across each result to filter out those having local similarity score below the given threshold. This suffers from generating an unnecessarily large number of intermediate results which are then discarded. Instead, we propose to process LS-queries by leveraging the \btsr index \cite{chatzig17btsr}, which can prune the search space simultaneously according to both criteria. 

% The most trivial approach to answer LS-queries would sequentially scan all geolocated time series and check whether each given constraint is satisfied. However, this is not realistic against large real-world datasets due to its exhaustive nature.
% Thus, to efficiently process LS-queries, we leverage the potential of the \btsr index \cite{chatzig17btsr}. With the \btsr index, pruning the search space can be done jointly in both domains. 

While traversing the \btsr, {\em spatial filtering} is performed at each node $N$ by computing the {\em bounding distance} $mindist_{sp}$ between the location of $T_q$ and the MBR of $N$, as in R-Trees~\cite{DBLP:conf/sigmod/RoussopoulosKV95}.
% $mindist_{sp}(T_q.loc, MBR_N)$

% Obviously, no location indexed under node $N$ can have smaller distance that this from query $T_q$. 
  
  
For {\em time series similarity}, we exploit the MBTS stored within each node. Considering an MBTS at a node $N$, we calculate its distance $mindist_{ts}^i$ from $T_q$ at each timestamp $i$ as:
  
\begin{equation}
 \begin{split}
  mindist_{ts}^i(T_q, {MBTS}_N) = \begin{cases}
	T_q^i - B_{N}^{\sqcap_{i}}, & \text{if} \;\; T_q^i > B_{N}^{\sqcap_{i}} \\
	B_{N}^{\sqcup_{i}} - T_q^i, & \text{if} \;\; T_q^i < B_{N}^{\sqcup_{i}} \\
	0, & \text{if} \;\; B_{N}^{\sqcap_{i}} \leq T_q^i \leq B_{N}^{\sqcup_{i}}
	  \end{cases}
 \end{split}
 \label{eq:mindist_ts}
\end{equation}

\noindent where $B_{N}^{\sqcap_{i}}$ and $B_{N}^{\sqcup_{i}}$ are the upper and lower values of the MBTS at timestamp $i$. By definition of MBTS, no time series indexed under $N$ can differ from $T_q$ by less than $mindist_{ts}^i$ at timestamp $i$. Hence, only at those timestamps that $mindist_{ts}^i \leq \epsilon$, it is possible that a time series indexed under $N$ is locally similar to $T_q$. Subsequently, we can compute a {\em local similarity bound} $\sigma_B$:
\begin{equation}
%\begin{split}
\sigma_{B}(T_q, MBTS_N, \epsilon) = max\{|I|; \forall i \in I, mindist^i_{ts}(T_q, MBTS_N) \leq \epsilon\}.
%\end{split}
\label{eq:sim_bound}
\end{equation}
\noindent that reflects the {\em maximum} interval $I$ of consecutive timestamps where the distance computed by Eq.~\ref{eq:mindist_ts} does not exceed margin $\epsilon$. 
This value is an upper bound of the local similarity scores of $T_q$ with any time series enclosed in this MBTS. Figure \ref{fig:sim_mbts} shows that $T_q$ deviates from the given MBTS by no more than $\epsilon$ during two intervals: one consisting of $|I_1|=5$ consecutive timestamps and a smaller one with only $|I_2|=2$ timestamps (shown as square points). So, the local similarity bound for this MBTS is $\sigma_{B}=5$.

\begin{figure}[tb]
    \centering
    \includegraphics{Figures/sim_mbts.png}
    \caption{Local similarity check against an MBTS.}
    \label{fig:sim_mbts}
\end{figure}

By construction, the MBTSs of a child node $N'$ get tighter bounds compared to those of its parent $N$ as we descend the \btsr. It is easy to verify that 
\begin{equation}
\begin{split}
\sigma_{B}(T_q, MBTS_N, \epsilon) \geq \sigma_{B}(T_q, MBTS_{N'}, \epsilon)
\end{split}
\label{eq:maxdur_ts}
\end{equation}
\noindent hence local similarity bounds can only diminish when descending the index. This bound provides a useful pruning condition during search with a cutoff threshold $\delta$. Any node where all its MBTSs have local similarity bound $\sigma_{B}$ below $\delta$ can be safely pruned.

Next, we describe a baseline approach that employs a sequential scan over MBTSs, and then we present an optimization that prioritizes selected \textit{checkpoints} to avoid many point-wise comparisons.


\subsection{Sweep Line Approach}
\label{sec:baseline}

%\checknote{Mention ``sweep line'' also in the description.}  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\eat{  

  that lower bounds the distance among the query and any geolocated time series indexed in node $N$ for that specific timestamp:
  
Consequently, for each timestamp, we check whether this $mindist_{ts}^i$ is less than, or equal to $\epsilon$. If this holds for at least $\delta$ consecutive timestamps, node $N$ might contain possible results in its sub-tree and we have to traverse it; otherwise, we can safely prune it. Figure \ref{fig:sim_mbts} depicts an example concerning the MBTS of a qualifying node. Supposing that $\delta=5$, there are exactly 5 consecutive timestamps where the time series satisfies the $\epsilon$ constraint.

\begin{figure}[tb]
    \centering
    \includegraphics{Figures/sim_mbts.png}
    \caption{Local similarity with a MBTS.}
    \label{fig:sim_mbts}
\end{figure}

Intuitively, considering an MBTS in a node $N$, and the corresponding list of intervals $\bar{I}_N$ that satisfy $mindist_{ts}$ in terms of $\delta$, the maximum duration of an interval $max(|I_N^x|), x = 1, ..., |\bar{I}_N|$ is an upper bound of the maximum duration intervals of its children. This local similarity bound can be more formally described as:

\begin{equation}
\begin{split}
\sigma_{B}(T_q, B_N) = max(|I_N^x|) \geq max(|I_{N'}^y|), \\
 x = 1, ..., |\bar{I}_N|,  y = 1, ..., |\bar{I}_{N'}|
\end{split}
\label{eq:maxdur_ts}
\end{equation}

\checknote{Isn't this equivalent to something like $local\_sim$ (at node level) introduced in Def. 1?}

\noindent where $\bar{I}_{N'}$ is the list of intervals that satisfy $mindist_{ts}$ in terms of $\delta$ for any child of $N$.

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


We explain how the \btsr can be used, in conjunction with a simple sweep-line algorithm, to answer each of the three LS-queries, taking advantage of the two types of bounds, $mindist_{sp}$ and $mindist_{ts}$, described above.


% In this method, we employ the \btsr to answer the three LS-queries by taking advantage of the aforementioned bounds in its nodes constructed for the spatial and time series domains.

\vspace{2mm}

\noindent $\mathbold{Q_{rr}(T_q, \rho, \epsilon, \delta)}$: We traverse the \btsr starting from its root. At each inner node $N$, we first check whether $mindist_{sp}(T_q, MBR_N)$ $\leq$ $\rho$. If so, we employ a sweep line across the time axis to compute the local similarity bound $\sigma_{B}(T_q, MBTS_N, \epsilon)$ for every MBTS included in $N$. If {\em all} resulting bounds $\sigma_{B}$ are below $\delta$, the subtree under $N$ is pruned. Otherwise, the search continues at the children. Upon reaching a leaf node, we fetch the geolocated time series contained therein, and verify the query constraints against each one. Each $T$ such that $d(T_q.loc, T.loc) \leq \rho$ and $\sigma(T_q, T, \epsilon) \geq \delta$ is added to the results.

\vspace{2mm}

\noindent $\mathbold{Q_{kr}(T_q, k, \epsilon, \delta)}$: We maintain a priority queue $P$ containing both inner nodes (sorted by ascending $mindist_{sp}$) and geolocated time series (sorted by ascending spatial distance to $T_q$). We start by adding to $P$ the root of \btsr. In each iteration, we retrieve the top element from $P$. If it is an inner node, we visit its children to calculate local similarity bounds $\sigma_B$ according to Eq.~\ref{eq:sim_bound}. For any child $N$ that $\sigma_B$ of one of its MBTSs satisfies threshold $\delta$, we search the subtree of $N$. Then, we calculate the corresponding spatial distance ($mindist_{sp}$ for a node $N$ or Euclidean distance for a geolocated time series $T$) and insert it back to $P$. Once we encounter a geolocated time series $T$ at the top of $P$, we add it to the results. The process terminates once $k$ geolocated time series have been obtained.

\vspace{2mm}

\noindent $\mathbold{Q_{rk}(T_q, \rho, \epsilon, k)}$: This query is evaluated similarly to the previous one, with two differences. The first difference is that the priority queue $P$ is now sorted based on local similarity bounds in descending order, instead of spatial distance bounds in ascending order. The second is that before inserting an item (node or time series) to $P$, its spatial distance ($mindist_{sp}$ or exact) is calculated, and if it is higher than $\rho$ the item is skipped. The traversal starts again from the root, and terminates once $k$ time series have been retrieved from the top of $P$. These are the top-$k$ results with respect to local similarity (if another time series $T$ had higher local similarity, it would have been retrieved from $P$ first), and they are located within range $\rho$ from $T_q$ (otherwise, they would not have been admitted to $P$). 


% \noindent $\mathbold{Q_{rk}(T_q, \rho, \epsilon, k)}$: \checknote{I think this is wrong! I believe it should be similar to the previous one, with the only difference of sorting the priority queue by local similarity scores instead of spatial distance!} We maintain two priority queues: $P$ holds inner nodes sorted by local similarity bounds (Eq.~\ref{eq:sim_bound}), $R$ keeps up to $k$ geolocated time series sorted by local similarity scores (as in Definition 1). Since this query does not specify a cutoff threshold $\delta$ for local similarity, we initially set $\delta=1$. We start by adding the \btsr root in the list $P$ of inner nodes. We then iteratively poll $P$, and for each inner node $N$ we encounter, we check if $mindist_{sp}(T_q, MBR_N) \leq \rho$. If $N$ qualifies spatially, we calculate the local similarity bounds of all its MBTS. Then, we assign the maximum of these bounds to node $N$ and we add it back to list $P$. If the top element in $P$ is a leaf, we add all its raw geolocated time series along with their local similarity scores $\sigma$ to list $R$. Once $R$ reaches $k$ elements, we set $\delta$ equal to the local similarity score $\sigma_k$ of its $k$-th element. List $R$ is updated when another raw time series has $\sigma \geq \delta$; in that case, its current $k$-th element is evicted to make room for the newly inserted one and $\delta$ is updated accordingly. Finally, once the top element in list $P$ has local similarity score less than $\delta$, we return the results contained in $R$. 

\subsubsection{Checkpoint Approach}
\label{sec:checkpoint}

% \checknote{Include reference to SSTD paper?}

The drawback of the sweep-line approach is that it needs to perform a comparison for each individual timestamp to eventually determine the exact or maximum local similarity of a given time series or node, respectively. In the following, we explain how we can use \textit{checkpoints} along the time axis to avoid this exhaustive search. These checkpoints prioritize specific timestamps when checking for candidate matches to eagerly filter out non-qualifying items.

% In the previous approach, we need to sweep over each timestamp and make value comparisons in order to calculate the local similarity for MBTS or raw geolocated time series. Since this is rather exhaustive, we now consider \textit{checkpoints} along the time axis, so that these specific timestamps are prioritized when checking for candidate matches, to avoid checking all timestamps and thus eagerly filter out non qualifying items.

Assume a query with local similarity threshold $\delta$. We can place checkpoints at every $\delta$ timestamps, and only apply the local similarity filter (i.e., $|T_q^{i} - T^{i}| \leq \epsilon$) at those. If no checkpoint satisfies the condition, this item can be safely pruned since it cannot have local similarity to $T_q$ at least $\delta$ (as this would require the condition to be true for at least $\delta$ consecutive timestamps, thus crossing at least one checkpoint).

\begin{figure}[!t]
 \centering
 \subfloat[Checkpoints placed every $\delta$ timestamps.]{\includegraphics[width=0.43\textwidth]{Figures/checkpoints.png}\label{fig:checkpoints}} \\
 \subfloat[Local similarity starting before checkpoint at $t'$.]{\includegraphics[width=0.43\textwidth]{Figures/proofLeft.png}\label{fig:proof1}} \\
 \subfloat[Local similarity ending after checkpoint at $t'$.]{\includegraphics[width=0.43\textwidth]{Figures/proofRight.png}\label{fig:proof2}}
 \vspace{-10pt} 
 \caption{Local time series similarity via checkpoints.}
 \label{fig:proof}
\end{figure}

Figure \ref{fig:checkpoints} shows an example with checkpoints placed along the time axis every $\delta=5$ timestamps. For clarity, we consider a single time series $T$. Assume a checkpoint at timestamp $t'$ and a minimal duration $\delta$ starting at timestamp $t'-\delta+1$ for asserting local similarity with query $T_q$, as shown with the grey strip in Figure \ref{fig:proof1}. This interval cannot have smaller duration, as it would not satisfy the $\delta$ constraint. Thus, the local similarity condition will evaluate to true at checkpoint $t'$. Similarly, if such an interval ends at timestamp $t'+\delta-1$ (Figure \ref{fig:proof2}), it will be detected at the checkpoint at $t'$. This observation entails that it suffices to check for local similarity only at checkpoints, i.e., every $\delta$ timestamps. We denote the set of checkpoints as $C$, determined at query time. If a checkpoint satisfies the condition, then we need to scan both forward and backward from it to determine the actual local similarity score, i.e., to find the exact extent of the time interval for which the condition holds.

% Since we skip timestamps and in order to avoid false negatives, we now have to verify matches along the time axis, but towards both directions, i.e., before and after a given checkpoint.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\eat{

This leads to the following observation.

\begin{mylemma}[Checkpoint Covering Interval]
Let the interval between successive checkpoints not exceed $\delta$. Considering a checkpoint placed at timestamp $t'$, a local similarity interval starting at $s, t'-\delta+1 \leq s < t'$ and ending at $f, t' < f \leq t'+\delta-1$ will satisfy all matching constraints at timestamp $t'$.
\end{mylemma}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%We can now further reduce the complexity when searching the \btsr, by introducing checkpoints placed every $\delta$ timestamps \textit{at query time}. This way, we avoid checking all time stamps, which requires significantly less comparisons, especially for long geolocated time series. 

Figure \ref{fig:sim_mbts_checkpoints} exemplifies the use of checkpoints for comparing $T_q$ to an MBTS of a node for $\delta=5$ timestamps. Instead of sequentially performing 11 comparisons until verifying that local similarity score $\sigma$ is at least $\delta$ (i.e., we stop the verification at $t=11$, once $\sigma=5$), we check only around the checkpoints. At the leftmost checkpoint $c_1$, no local similarity is found ($T_q$ is farther than $\epsilon$ from the MBTS), so we skip directly to checkpoint $c_2$. Since $T_q$ differs by less than $\epsilon$ at $c_2$, we need to compare values backward and forward, up to the previous and next checkpoint, respectively. This requires only 6 comparisons instead of 11 to decide that this node may contain candidates. Next, we describe how probing with checkpoints is applied during evaluation of LS-queries.

\begin{figure}[tb]
    \centering
    \includegraphics{Figures/sim_mbts_checkpoints.png}
    \caption{Local similarity with a MBTS using checkpoints.}
    \label{fig:sim_mbts_checkpoints}
\end{figure}


\vspace{2mm}

\noindent $\mathbold{Q_{rr}(T_q, \rho, \epsilon, \delta)}$: Algorithm \ref{alg:query_r} outlines the procedure. Initially, we obtain the children of the root node in a list and place the checkpoints every $\delta$ timestamps (Lines 1-3). We iterate over each item $N$ in this list. If $N$ is an inner node, we have to examine whether both constraints with respect to $\rho$ and $\delta$ are met for each of its children. Verification of MBTS against query $T_q$ will be discussed shortly. If this is the case, we traverse the sub-tree of each child in the same manner, by adding it to the list (Lines 7-11), thus descending the tree. If the examined node is a leaf (Line 12), we iterate over each contained time series $T$ to check the constraints $\rho$ and $\delta$. If $T$ qualifies, it is added to the results (Lines 13-15). Note that now the calculation of local similarity scores for geolocated time series is based on checkpoints (Line 14), as discussed above.

Verification of MBTS against the local similarity constraints $\epsilon, \delta$ is applied using checkpoints (Lines~17-38). This verification concerns each MBTS in a given node $N'$. At each checkpoint $c$, we first verify whether its $mindist_{ts}^c$ to query $T_q$ is at most $\epsilon$ (Line 20). If so, we first scan backward to inspect whether there are at least $\delta$ consecutive timestamps where $T_q$ deviates by at most $\epsilon$ from this MBTS (Lines 22-29). Similarly, we probe forward from checkpoint $c$ (Lines 30-37). In either case, once local similarity no longer holds at a timestamp, probing skips to the next checkpoint. If the check fails for all checkpoints of all MBTSs, then this node cannot contain any results (Line 38).

\SetAlFnt{\small}
\begin{algorithm}[tb]
	\DontPrintSemicolon
	\vspace{4pt}
	$R \leftarrow \emptyset$ \\
	$List \leftarrow Root.entries$ \\
	$C \leftarrow determineCheckpoints(\delta)$ \\
	\While{$List \neq \emptyset$}{
		$N \leftarrow List.getNext()$ \\
		\If{$N$ is not leaf}{
			\ForEach{$N' \in N.getChildren()$}{
				\If{$mindist_{sp}(T_q, MBR_{N'}) \leq \rho$}{
				    $count \leftarrow \emptyset$ \\
                    \If{$VerifyMBTS(T_q, N', C, \epsilon, \delta)$}{
                        $List \leftarrow List \cup \{N'.getChildren()\}$ \\
                    }
				}
			}
		}
		\Else{
			\ForEach{$T \in N.getObjects()$}{
				\If{$d(T_q, T) \leq \rho \land \sigma^C(T_q, T, \epsilon) \geq \delta$}{
					$R \leftarrow R \cup \{ T \}$ \\
				}
			}
			\KwRet R
		}
	}
	
	\vspace{4pt}
    \SetKwProg{verifyMBTS}{Procedure}{}{}
    \verifyMBTS{$VerifyMBTS(T_q, N', C, \epsilon, \delta)$}{
        \ForEach{$MBTS \in N'$}{
    	    \ForEach{$c \in C$}{
                \If{$mindist_{ts}^c(T_q, MBTS) \leq \epsilon$}{
                    $count++, c' \leftarrow c$ \\
                    \While{True}{
                        $c'--$ \\
                        \If{$mindist_{ts}^{c'}(T_q, MBTS) \leq \epsilon$}{
                            $count++$ \\
                            \If{$count \geq \delta$}{
                                \KwRet True
                            }
                        }
                        \Else{
                            $break$
                        }
                    }
                    \While{True}{
                        $c++$ \\
                        \If{$mindist_{ts}^c(T_q, MBTS) \leq \epsilon$}{
                            $count++$ \\
                            \If{$count \geq \delta$}{
                                \KwRet True
                            }
                        }
                        \Else{
                            $break$
                        }
                    }
                } 
            }
        }
        \KwRet $False$
	}

	\caption{$Q_{rr}(T_q, \rho, \epsilon, \delta)$}
	\label{alg:query_r}
\end{algorithm}


\vspace{2mm}

\noindent $\mathbold{Q_{kr}(T_q, k, \epsilon, \delta)}$: We follow a similar procedure to the one in Section~\ref{sec:baseline} for query $Q_{kr}$, employing the same verification process over MBTSs and time series as in Algorithm~\ref{alg:query_r}. Algorithm~\ref{alg:query_k} describes the procedure. We start by adding the root node to a priority queue $P$ based on spatial distance (Line 2). After determining the checkpoints using the given $\delta$ (Line 3), we iteratively retrieve elements from $P$ (Line 5). Then, three cases may occur: 
\begin{enumerate}
\item[(i)] If this element is a time series (Lines 6-9), it is guarranteed to be a result, given that $P$ is sorted based on spatial distance from $T_q$. Indeed, any subsequent element must be located farther than the current. When list $R$ obtains the required number $k$ of results, the search terminates. 
\item[(ii)] The element is a leaf node (Lines 10-14): In this case, we obtain each time series $T$ contained in this leaf, and verify the local similarity score of $T$ against $\delta$. If the condition is met, we calculate the spatial distance of candidate $T$ from query $T_q$ and push $T$ into the priority list along with its spatial distance (Lines 10-14). 
\item[(iii)] If the element is an inner node, we iterate over its children and only push back to the queue the ones whose MBTSs are verified against $\epsilon$ and $\delta$ using checkpoints (Lines 15-19).
\end{enumerate}

\SetAlFnt{\small}
\begin{algorithm}[!t]
	\DontPrintSemicolon
	$R \leftarrow \emptyset$ \\
	$P.push(Root)$ \\
	$C \leftarrow determineCheckpoints(\delta)$ \\
	\While{$P$ is not empty}{
		$N \leftarrow P.poll()$ \\
		\If{$N$ is raw}{
				$R \leftarrow R \cup \{ N \}$ \\
			\If{$|R| = k$}{
				$break$ \\
			}
		}
		\ElseIf{$N$ is leaf}{
			\ForEach{$T \in N.getObjects()$}{
				\If{$\sigma^C(T_q, T, \epsilon) \geq \delta$}{
					 $T.dist \leftarrow d(T_q, T)$ \\
					 $P.push(T, T.dist)$ \\					 
				}					
			}
		}
		\Else{
			\ForEach{$N' \in N.getChildren()$}{
				\If{$VerifyMBTS(T_q, N', C, \epsilon, \delta)$}{
					$N'.dist \leftarrow mindist_{sp}(T_q, MBR_{N'})$ \\
					$P.push(N', N'.dist)$ \\	
				}
			}
		}
	}
	\KwRet R
	\caption{$Q_{kr}(T_q, k, \epsilon, \delta)$}
	\label{alg:query_k}	
\end{algorithm}

\vspace{2mm}

\noindent $\mathbold{Q_{rk}(T_q, \rho, \epsilon, k)}$: The procedure for this query is listed in Algorithm~\ref{alg:query_ks}. Notice that for employing checkpoints, we need a local similarity threshold $\delta$, so as to determine their placement, but this query does not specify a fixed $\delta$. To be able to obtain one during search, we now maintain two priority queues: $P$ holds inner nodes sorted by local similarity bounds (Eq.~\ref{eq:sim_bound}), while $R$ keeps up to $k$ geolocated time series sorted by local similarity scores (as in Def. 1). We initially set $\delta=1$, so checkpoints are trivially placed at every timestamp. This implies that computation of local similarity scores with $\delta=1$ is equivalent to the sweep line approach. However, $\delta$ increases with the detection of qualifying results, hence checkpoints will progressively get placed more sparsely. The search starts by adding the \btsr root in $P$ (Line 2). We iteratively poll the top element from $P$, and there are two possible cases:
\begin{enumerate}
\item[(i)] The top element is a leaf node. Then, we iterate over the contained time series and add the ones that satisfy the spatial condition ($\rho$) to $R$, along with their corresponding local similarity score $\sigma$ if it exceeds the current value of $\delta$ (Lines 8-12).
Once $R$ exceeds capacity $k$, its last element is evicted to make room for the newly inserted one and $\delta$ is updated according to the local similarity score $\sigma_k$ of the $k$-th element in $R$. In this case, the placement of checkpoints is re-adjusted according to the increased $\delta$ value (Lines 13-16).

\item[(ii)] The top element is an inner node. In this case, we iterate over each child $N'$ and check if $mindist_{sp}(T_q, {MBR_N'}) \leq \rho$. If $N'$ qualifies, we calculate the local similarity bound $\sigma_B$ of all its MBTSs using checkpoints. If the maximum among these bounds $max(\sigma_B) \geq \delta$, then $N'$ is inserted to $P$ with this maximum score (Lines 17-25).
\end{enumerate}

The process terminates once the top element in $P$ has local similarity less than $\delta$ (Lines 6-7). The result is the contents of $R$.


\SetAlFnt{\small}
\begin{algorithm}[!t]
	\DontPrintSemicolon
	$R \leftarrow \emptyset$ \\
	$P.push(Root)$ \\
	$\delta \leftarrow 1$ \\
	$C \leftarrow determineCheckpoints(\delta)$ \\
	\While{$P$ is not empty}{
		\If{$P.peekFirst.\sigma_B < \delta$}{
		    $break$ \\
		}
		\If{$N$ is leaf}{
			\ForEach{$T \in N.getObjects()$}{
				\If{$d(T_q, T) \leq \rho$}{
					 %$T.\sigma \leftarrow \sigma^C(T_q, T, \epsilon)$ \\
					 \If{$\sigma^C(T_q, T, \epsilon) \geq \delta$}{
					    $R.push(T, \sigma^C(T_q, T, \epsilon))$ \\					 
					 }
				}
				\If{$R.size > k$}{
				    $R.pollLast$ \\
				    $\delta \leftarrow R.peekLast.\sigma$ \\
				    $C \leftarrow determineCheckpoints(\delta)$ \\
			    }
			}
		}
		\Else{
			\ForEach{$N' \in N.getChildren()$}{
				\If{$mindist_{sp}(T_q, MBR_{N'}) \leq \rho$}{
				    $\sigma_B \leftarrow 0$ \\
				    \ForEach{$MBTS \in N'$}{
				        \If{$\sigma_B^C(T_q, MBTS, \epsilon) \geq \sigma_B$}{
				            $\sigma_B \leftarrow \sigma_B^C(T_q, MBTS, \epsilon)$
				        }
				    }
					\If{$\sigma_B \geq \delta$}{
					    $P.push(N', \sigma_B)$ \\	
					}
				}
			}
		}
	}
	\KwRet R
	\caption{$Q_{rk}(T_q, k, \rho)$}
	\label{alg:query_ks}	
\end{algorithm}








\subsection{The \texorpdfstring{\sbtsr} IIndex}
\label{sec:sbtsr_index}

\subsubsection{Index Structure}
\label{subsec:structure_sbtsr}
The \btsr index uses $k$-means clustering to cluster the time series under each node and then stores the MBTSs of those clusters. However, clustering entire time series typically generates many overlapping MBTSs, incurring much dead space. This has a negative impact on the pruning power of the index, especially when considering local similarities. Figure~\ref{subfig:bundles} depicts such a case of six time series indexed in a node. A $k$-means clustering with $k=3$ will form the depicted MBTSs denoted with shaded colors. As a result, the dark area $A$ represents the overlap between $mbts.1$ and $mbts.2$ and actually makes those bounds less tight. Hence, such MBTSs inflate estimates for local similarity bounds, and thus lead to unnecessarily descending further down the index.

To reduce the amount of overlap within the MBTSs of nodes, we introduce an extended version of the \btsr, named \sbtsr. \sbtsr attempts to eliminate as much overlap as possible, through segmentation of time series. Figure~\ref{subfig:bundles_part} depicts the intuition. If we segment the time series before applying $k$-means, the resulting MBTSs for each segment tend to be tighter, eliminating the excessive overlap $A$ from Figure~\ref{subfig:bundles}. The \sbtsr is built similarly to \btsr. The only difference is that the MBTSs of each node are calculated \textit{per segment}. In this method, we assume a pre-defined number $s$ of segments, but segmentation is orthogonal to our problem and can be carried out by applying existing methods like \cite{bingham2006segmentation}. Ultimately, \sbtsr allows for more aggressive pruning when traversing the index.


\begin{figure}[tb]
 \centering
 \subfloat[Example of a node's MBTS.]{\includegraphics[width=0.43\textwidth]{Figures/bundles_node.png}\label{subfig:bundles}} \\
 \subfloat[Segmenting can eliminate whitespace.]{\includegraphics[width=0.43\textwidth]{Figures/bundles_node_partition.png}\label{subfig:bundles_part}}
 \vspace{-10pt} 
 \caption{Segmenting time series yields more tight MBTS.}
 \label{fig:proof_partition}
\end{figure}



\subsubsection{Cross-Segment Continuity Via Bit-Vectors}
\label{subsec:bit_vectors}
A downside of the segmentation approach is the loss of the MBTS continuity across time, which results in MBTSs enclosing different time series in neighboring segments. For example, in Figure~\ref{subfig:bundles_part}, there are no MBTSs in the right segment containing the same time series as $mbts1.1$ and $mbts1.2$, a fact which hinders the calculation of local similarity on the segment boundaries (the vertical line). To overcome this, we introduce a \textit{bit-vector} $V$ along each MBTS of a segment, having one bit for each MBTS created. If in the current segment a bit in vector $V$ of a given MBTS is set, this indicates that this MBTS encloses at least one common time series with another MBTS$'$ in the next segment. In the example shown in Figure~\ref{subfig:bundles_part}, $V=110$ for $mbts1.1$ indicates common time series with $mbts2.1$ and $mbts2.2$ in the next segment, while $V=001 $ for $mbts1.3$ signifies common time series with only $mbts2.3$. This way, to calculate local similarity, we can easily identify all the MBTSs that share common time series among two successive segments. 

To evaluate LS-queries, traversal of the \sbtsr index follows a similar rationale to the procedure in Section~\ref{sec:checkpoint}. For each checkpoint $c$, we first obtain the segment where it falls in, and we scan each MBTS leftward and rightward from $c$, as discussed in Section~\ref{sec:checkpoint}. If we cross the border to another segment, the available bit-vectors directly identify the MBTS that need be examined in this neighboring segment. This propagates until the local similarity constraints ($\epsilon$ and $\delta$) are satisfied. Figure~\ref{fig:part_checkpnt} illustrates an example of a node verification. Let us consider a predetermined number of three segments and the corresponding MBTS of each segment for that node. Suppose that there exists a checkpoint $c$ on the second segment. To verify whether this node satisfies the local similarity constraints, we start from checkpoint $c$ and we check leftwards whether $mindist_{ts}^{i} \leq \epsilon$ for each timestamp. If the currently examined timestamp falls in the first segment, we fetch the corresponding MBTS and bit-vectors and continue checking whether $mindist_{ts}^{i} \leq \epsilon$ in both MBTS (green shaded), as their bit-vectors both indicate common members with the first one in segment 2. A similar procedure is followed rightwards, where we only have to check the first MBTS, according to the bit-vectors.

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.43\textwidth]{Figures/partition_checkpoint_check.png}
    \caption{Example of verifying a \sbtsr node.}
    \label{fig:part_checkpnt}
\end{figure}