\subsection{Related Work}
\label{sec:related}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
Similarity search 
    whole sequence matching 
    subsequence matching
    Correlation (3-4 lines)
Clustering of time series 
Flocks trajectories (mention all related problems -moving clusters, swarms etc, but our problem is more related to flocks)
\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%



 
\textbf{Time series similarity.} 
Similarity search over time series has attracted a lot of research interest~\cite{DBLP:journals/pvldb/EchihabiZPB18}. One well-studied family of approaches includes wavelet-based methods~\cite{chan1999icde}, which rely on \emph{Discrete Wavelet Transform}~\cite{graps1995cse} to reduce the dimensionality of time series and generate an index using the coefficients of the transformed sequences. The \emph{Symbolic Aggregate Approximation} (SAX) representation~\cite{jessica2007dmkd} has led to the design of a series of indices, including $i$SAX~\cite{shieh2008kdd}, $i$SAX 2.0~\cite{camerra2010icdm}, $i$SAX2+~\cite{camerra2014kais}, ADS+~\cite{zoumpatianos2014sigmod}, Coconut~\cite{DBLP:journals/pvldb/KondylakisDZP18}, DPiSAX~\cite{dpisaxjournal}, and ParIS~\cite{DBLP:conf/bigdataconf/PengFP18}. However, these indices support similarity search over complete time series, i.e. whole-matching. Recently, the \textit{ULISSE} index was proposed~\cite{linardi2018scalable}, which is the first index that can answer similarity search queries of variable length. 
%Based on $i$SAX and constructed over a large number of time series of possibly different lengths, it supports both approximate and exact \textit{k-nearest neighbor} queries.

% However, its processing scheme requires a specific query time series as input, for which the $k$ most similar results are retrieved, whereas we are interested in discovering locally similar pairs and bundles of time-aligned subsequences.

Moreover, many approaches have been proposed for \textit{subsequence matching}. In this problem, a query subsequence is provided and the goal is to identify matches of it across one or more time series, typically of large length. The \textit{UCR suite} \cite{rakthanmanon2012searching} offers a framework comprising four different optimizations regarding subsequence similarity search. In computing \textit{full-similarity-joins} over large collections of time series, i.e., to detect for each possible subsequence its \textit{nearest neighbor}, the \textit{matrix profile}~\cite{yeh2016matrix} keeps track of Euclidean distances among each pair within a \textit{similarity join set} (i.e., a set containing pairs of each subsequence with its nearest neighbor).

The problem we address in this paper differs from the above settings. Instead of identifying matches of a query subsequence against one, or more time series, we are interested in discovering locally similar pairs and bundles of time-aligned subsequences within a given collection of time series.


% However, a query time series is required to search for potential matches, which does not hold in our setting concerning pairs (i.e., joins) over subsequences.

% In contrast, for each subsequence we find all its possible matches within a given deviation in value per timestamp, and not a single subsequence with the smallest Euclidean distance. Several approaches have also been proposed for time series similarity, efficiently indexing large amounts of time series data.





\begin{comment}
In \cite{yeh2016matrix}, the authors tackle the problem of time series subsequences \textit{all-pairs-similarity-search}, or \textit{full similarity joins}, as it is mostly regarded in the literature. The authors are interested in full similarity joins on all possible subsequences of one (self-join) or two given time series, that is, for each possible subsequence, detect its \textit{nearest neighbor}. They introduce the \textit{matrix profile}, which is a vector of the Euclidean distances among each pair within a \textit{similarity join set} (i.e., a set containing pairs of each subsequence with its nearest neighbor). They also introduce the \textit{matrix profile index} that contains the actual locations of the nearest neighbor of each subsequence. Matrix profile and its index are themselves the result of the full joins.
\end{comment}

\begin{comment}
After defining a \textit{mindist} that is calculated among a given query and a time series envelope held within each node, they introduce approximate and exact \textit{k-nearest neighbors} search solutions. 
\end{comment}

\textbf{Correlated time series.}
Identifying similar subsequences between time series also indicates some {\em correlation} between them. Several approaches compute pairwise statistics (e.g., Pearson correlation, beta values) especially in streaming time series \cite{zhu2002statstream,cole2005fast,papadimitriou2006local}. There are also works concerning {\em co-evolving} time series data, either towards detecting and correcting missing values \cite{yongjie2015fast} or mining typical patterns and points of variation to achieve a meaningful segmentation of large time series \cite{matsubara2014autoplait}. However, none of these approaches is applicable to our setting, where we require similarity in the time series values. 



\begin{comment}
In the time series literature, there are numerous works that attempt to find possibly correlated subsequences among a set of time series, or within a time series itself. Zhu et al. \cite{zhu2002statstream} introduce \textit{StatStream}, a system for monitoring tens of thousands of  time series in an online fashion. It provides --among other-- pairwise statistics (e.g., correlation, beta value) for specific windows considered over the streams. They consider three temporal spans (i.e., landmark windows, sliding windows and damped windows) that are consisted of basic windows of specific length. In \cite{cole2005fast}, the authors introduce the notion of \textit{uncooperative} time series, that is, time series in which the energy is spread over many frequency components. This approach is a combination of simple techniques for the calculation of the \textit{Pearson} correlation on such uncooperative streaming time series. Despite the streaming nature of the problem, the authors assume that, apart from a one-pass initial filtering step, a second pass may search the previous data using a well-organized and potentially growing data structure. A Spark implementation of such a data structure is presented in \cite{levchenko2018spark} is a \textit{sketch-based} index for a large collection of time series. The index is built in parallel, by exploiting the sketch (i.e., inner products of a time series to a set of random vectors) properties of time series at lower dimensions. Finally, Papadimitriou et al. \cite{papadimitriou2006local} attempt to tackle the problem of efficiently computing a \textit{local} correlation score among a pair of time evolving time series, that captures more complex relationships. They introduce the \textit{LoCo} (Local Correlation) score at a timestamp, that is based on observations in the neighborhood of that instance. Initially, they measure \textit{autocovariance} by considering a sliding or exponential window around a timestamp $t$. Then, they extract the LoCo score using the \textit{eigenvectors} of the local autocovariance matrices and the corresponding eigenvectors with the largest eigenvalue. Contrary to ours, all the above methods focus on streaming data. Moreover, their main focus is the efficient calculation of correlation among time series subsequences instead of locating locally similar ones.

\checknote{Co-evolving time series.}
There are some works in the literature that focus on co-evolving time series, but from a different perspective. In \cite{yongjie2015fast}, the authors deal with the problem of detecting and correcting missing values on networks of co-evolving time series data. To achieve this, they reduce the problem to a \textit{collaborative filtering} one, and solve it via \textit{matrix factorization}. Finally, in \cite{matsubara2014autoplait}, the authors present \textit{AutoPlait}, a scalable, automatic mining algorithm for co-evolving time series that operates on large datasets and finds similar segment groups that agree with human intuition. Given a large collection of co-evolving time series, they find the typical patterns and the points of variation, so as to statistically summarize all sequences and achieve a meaningful segmentation.
\end{comment}

\textbf{Time series clustering.}
Our work also relates to {\em clustering of time series}, where methods perform either partitioning or density-based clustering. In the former class, algorithms typically partition the time series into $k$ clusters. Similarly to iterative refinement employed in $k$-means, the $k$-Shape partitioning algorithm~\cite{Paparrizos:2015:KEA:2723372.2737793,Paparrizos:2017:FAT:3086510.3044711} aims to preserve the shapes of time series assigned to each cluster by considering the shape-based distance, a normalized version of the cross-correlation measure between time series. In contrast, density-based clustering methods are able to identify clusters of time series with arbitrary shapes. YADING~\cite{Ding:2015:YFC:2735479.2735481} is a highly efficient and accurate such algorithm, which consists of three steps: it first samples the input time series also employing PAA (Piecewise Aggregate Approximation) to reduce the dimensionality, then applies multi-density clustering over the samples, and finally assigns the rest of the input to the identified clusters. However, clustering methods consider time series in their entirety and not matching subsequences as we consider in this work.

\textbf{Discovery of movement patterns in trajectories.}
Our work also relates to approaches for discovering clusters of moving objects, in particular a type of movement patterns that is referred to as {\em flocks}~\cite{gudmundsson2006computing}. A flock is a group of at least $m$ objects moving together within a circular disk of diameter $\epsilon$ for at least $\delta$ consecutive timestamps. Finding an exact flock is NP-hard, hence this work suggests an \textit{approximate} solution to find the \textit{maximal} flock from a set of trajectories using computational geometry concepts. In \cite{benkert2008reporting}, another \textit{approximate} solution for detecting all flocks is based on a skip-quadtree that indexes sub-trajectories. Flock discovery over {\em streaming} positions from moving objects was addressed in \cite{vieira2009line}. This \textit{exact} solution discovers flock disks that cover a set of points at each timestamp. Their flock discovery algorithm finds candidate flocks per timestamp and joins them with the candidate ones from the previous timestamps, reporting a flock as a result when it exceeds the time constraint $\delta$. An improvement over this technique was presented in \cite{tanaka2015efficient}, using a \textit{plane sweeping} technique to accelerate detection of object candidates per flock at each timestamp, while an inverted index speeds up comparisons between candidate disks across time. In our setting, detection of bundles is similar to flocks, thus for our baseline method we adapt the algorithm from \cite{vieira2009line}.

%  \red{In {\em convoy} discovery~\cite{Jeung:2008:DCT:1453856.1453971}, objects are allowed to organize in arbitrary shapes (convoys), and not necessarily in circular disks. Constraints for convoys were further relaxed to introduce the notion of {\em swarm}~\cite{DBLP:journals/pvldb/LiDHK10}, where moving objects are allowed to join groups sporadically even for non consecutive time intervals. Discovering traveling companions~\cite{DBLP:conf/icde/TangZYHLHP12}, i.e., groups of moving objects that travel together for some time applies to a streaming context, i.e., real-time position updates from evolving trajectories. The notion of {\em moving cluster}~\cite{Kalnis:2005:DMC:2156226.2156254} captures a pair of spatial clusters that have many common objects at two consecutive timestamps (snapshots), indicating a cluster that moved between these two timestamps. However,}
 
% \red{It is proven that if there is a disk with diameter $\epsilon$ that covers all trajectories in a flock, then there exists another disk with the same diameter but with different center that also covers all points and has at least two common points on its circumference. Based on this observation,} 

% \red{Overall, in time series we cannot apply purely geometric concepts (e.g., circular disks, spatial indexing) for detecting patterns, as done in methods concerning movement of objects over a 2-dimensional Euclidean space, hence our approach is distinct.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
There are various works in the trajectory literature that attempt to solve a similar problem, but in two dimensions. In \cite{gudmundsson2006computing}, the authors introduce the \textit{fixed-flock} (mentioned as \textit{flock} from this point on) discovery, which attempts to detect groups of objects of size at least $m$, that move together within a pre-specified disk of diameter $\epsilon$ for at least $\delta$ consecutive timestamps. They perform a hardness evaluation of the problem and show that finding an exact flock is NP-hard. They present an \textit{approximate} solution that attempts to find the \textit{maximal} flock from a set of trajectories using computational geometry. In \cite{benkert2008reporting}, the same authors provide an \textit{approximate} solution for detecting all flocks from a trajectory dataset that uses a \textit{skip-quadtree}. They introduce three approximation methods, based on the same approach: take all possible intervals and for each one, map all the sub-trajectories on a higher dimensional space and construct a skip-quadtree on the results; then, for each sub-trajectory, perform an approximate range query. The first \textit{exact} solution to the problem, running in polynomial time and on streaming data, was proposed in \cite{vieira2009line}, where the authors introduce a method that, at each time step, discovers flock discs that cover a set of points, after proving that, if there is a disk with diameter $\epsilon$ that covers all trajectories in a flock, then there exists another disk with the same diameter but with different center that also covers all points and has at least two common points on its circumference. Next, they introduce a basic flock discovery algorithm, which finds candidate flocks per time step and joins them with the candidate flocks from the previous steps, reporting a flock as a result when it exceeds the time constraint. Finally, in \cite{tanaka2015efficient}, the authors introduce a method that solves the above problem more efficiently using a \textit{plane sweeping} technique. We attempt to solve a similar problem to the above approaches, but in a time series setting where there is only one dimension per timestamp. Also, we focus on offline bundle detection.
\end{comment}